{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, csv, pickle\n",
    "from xml.dom import minidom\n",
    "from xml.etree import ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import  walkData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_path_of_all_xml_file():\n",
    "\tinput_file = \"../data/trials/all_xml.txt\"\n",
    "\twith open(input_file, 'r') as fin:\n",
    "\t\tlines = fin.readlines()\n",
    "\tinput_file_lst = [i.strip() for i in lines]\n",
    "\treturn input_file_lst## 优化text_encoder\n",
    "## 优化text_encoder\n",
    "input_file_lst = get_path_of_all_xml_file()## 优化text_encoder\n",
    "print(len(input_file_lst),input_file_lst[:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tags2key(tags: list):\n",
    "    return '_'.join(tags)\n",
    "\n",
    "\n",
    "def xml_file2text(xml_file,my_list):\n",
    "    tree = ET.parse(xml_file)\n",
    "\n",
    "    result = []\n",
    "    for tags in my_list:\n",
    "        root = tree.getroot()\n",
    "        for tag in tags:\n",
    "            if root:\n",
    "                root = root.find(tag)\n",
    "            else:\n",
    "                break\n",
    "        try:\n",
    "            result.append(root.text)\n",
    "        except:\n",
    "            result.append(\"\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def find_text(my_list, LEN=len(input_file_lst)):\n",
    "    result_dict = {}\n",
    "    key_list=[]\n",
    "    if len(my_list)==0 or LEN<=0:\n",
    "        return\n",
    "    if LEN > len(input_file_lst):\n",
    "        LEN=len(input_file_lst)\n",
    "    for tags in my_list:\n",
    "        key=tags2key(tags)\n",
    "        result_dict[key]=[]\n",
    "        key_list.append(key)\n",
    "    for file in tqdm(input_file_lst[:LEN]):\n",
    "        result = xml_file2text(f\"../data/{file}\",my_list)\n",
    "        for i in range(len(my_list)):\n",
    "            result_dict[key_list[i]].append(result[i])\n",
    "    return result_dict\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_list=[['id_info', 'nct_id'],['study_type'],['brief_title'],['official_title'],['oversight_info', 'has_dmc'],\n",
    "         ['brief_summary', 'textblock'], ['detailed_description', 'textblock'], ['overall_status'], ['start_date'], ['completion_date'],[ 'phase'], ['study_design_info', 'observational_model'], ['study_design_info', 'time_perspective'],['study_design_info' ,'intervention_model'],['study_design_info' ,'primary_purpose'],['study_design_info' ,'masking'],['condition'],['primary_outcome', 'time_frame'],['number_of_groups'],['enrollment'],['location_countries', 'country']]\n",
    "my_dict = find_text(my_list, 10000)\n",
    "key_list=list(map(tags2key, my_list))\n",
    "print(my_dict.keys())\n",
    "print(key_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def lazy_find(i):\n",
    "    print(key_list[i], set(my_dict[key_list[i]]))\n",
    "\n",
    "lazy_find(-3)\n",
    "\n",
    "# my_dict['study_type']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# my_dict['brief_title']\n",
    "'0'+'1'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def xml_file2tag(xml_file,my_list):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    study_type = root.find('study_type').text\n",
    "    if study_type != 'Interventional':\n",
    "        return ''\n",
    "    interventions = [i for i in root.findall('intervention')]\n",
    "    drug_interventions = [i.find('intervention_name').text for i in interventions \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tif i.find('intervention_type').text=='Drug']\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t# or i.find('intervention_type').text=='Biological']\n",
    "    if len(drug_interventions)==0:\n",
    "        return ''\n",
    "    result = []\n",
    "    for tags in my_list:\n",
    "        root = tree.getroot()\n",
    "        for tag in tags:\n",
    "            # print(tag)\n",
    "            if root:\n",
    "                root = root.find(tag)\n",
    "            else:\n",
    "                break\n",
    "        try:\n",
    "            # result.append(root.text)\n",
    "            child_list=[child.tag for child in root]\n",
    "            # for child in root:\n",
    "            #     child_list.append(child)\n",
    "            result.append(child_list)\n",
    "        except:\n",
    "            result.append(\"\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def find_tag(my_list, LEN=len(input_file_lst)):\n",
    "    result_dict = {}\n",
    "    key_list=[]\n",
    "    if len(my_list)==0 or LEN<=0:\n",
    "        return\n",
    "    if LEN > len(input_file_lst):\n",
    "        LEN=len(input_file_lst)\n",
    "    for tags in my_list:\n",
    "        key=tags2key(tags)\n",
    "        result_dict[key]=[]\n",
    "        key_list.append(key)\n",
    "    for file in tqdm(input_file_lst[:LEN]):\n",
    "        result = xml_file2tag(f\"../data/{file}\",my_list)\n",
    "        if result=='':\n",
    "            continue\n",
    "        for i in range(len(my_list)):\n",
    "            result_dict[key_list[i]].append(result[i])\n",
    "    return result_dict\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_list=[['study_design_info'], ['intervention'], ['arm_group'],['secondary_outcome']]\n",
    "tag_dict = find_tag(tag_list, 10000)\n",
    "tagkey_list=list(map(tags2key, tag_list))\n",
    "print(tag_dict.keys())\n",
    "print(tagkey_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def flatten(nested_list):\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):  # 如果是子列表，递归调用 flatten 函数\n",
    "            flat_list.extend(flatten(item))\n",
    "        else:\n",
    "            flat_list.append(item)  # 否则直接添加到结果列表\n",
    "    return flat_list\n",
    "\n",
    "def taglazy_find(i):\n",
    "    print(tagkey_list[i], set(flatten(tag_dict[tagkey_list[i]])))\n",
    "\n",
    "taglazy_find(0)\n",
    "# my_dict['study_type']\n",
    "# flattened_list = flatten(tag_dict['study_design_info'])\n",
    "# print(set(flattened_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def xml_file2alltext(xml_file,my_list):\n",
    "    tree = ET.parse(xml_file)\n",
    "    result = []\n",
    "    for tags in my_list:\n",
    "        root = tree.getroot()\n",
    "        cnt=0\n",
    "        outcome=[]\n",
    "        elements=[]\n",
    "        root = root.findall(tags[0])\n",
    "        for tag in tags[1:]:\n",
    "            if root:\n",
    "                for e in root:\n",
    "                    e = e.findall(tag)\n",
    "                    elements.extend(e)\n",
    "                root = elements\n",
    "                elements=[]\n",
    "            else:\n",
    "                break\n",
    "        try:\n",
    "            for e in root:\n",
    "                cnt+=1\n",
    "                outcome.append(e.text)\n",
    "            result.append([cnt]+outcome)\n",
    "        except:\n",
    "            result.append([0, ''])\n",
    "\n",
    "    return result\n",
    "\n",
    "def find_alltext(my_list, LEN=len(input_file_lst)):\n",
    "    result_dict = {}\n",
    "    key_list=[]\n",
    "    if len(my_list)==0 or LEN<=0:\n",
    "        return\n",
    "    if LEN > len(input_file_lst):\n",
    "        LEN=len(input_file_lst)\n",
    "    for tags in my_list:\n",
    "        key=tags2key(tags)\n",
    "        result_dict[key]=[]\n",
    "        key_list.append(key)\n",
    "    for file in tqdm(input_file_lst[:LEN]):\n",
    "        result = xml_file2alltext(f\"../data/{file}\",my_list)\n",
    "        for i in range(len(my_list)):\n",
    "            result_dict[key_list[i]].append(result[i])\n",
    "    return result_dict\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnt_list=[['id_info', 'nct_id'],['primary_outcome', 'time_frame'],['secondary_outcome','time_frame'],['primary_outcome'],['secondary_outcome'], ['intervention'], ['condition'], ['location'], ['arm_group'],['condition_browse','mesh_term'],['intervention_browse','mesh_term']]\n",
    "cnt_dict = find_alltext(cnt_list,10000)\n",
    "cntkey_list=list(map(tags2key, cnt_list))\n",
    "print(cnt_dict.keys())\n",
    "print(cntkey_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def alltextlazy_find(i,LEN):\n",
    "    print(cntkey_list[i], set(flatten(cnt_dict[cntkey_list[i]][:LEN])))\n",
    "alltextlazy_find(3,10000)\n",
    "set(flatten(cnt_dict['secondary_outcome_time_frame']))\n",
    "# for idx, e in enumerate(cnt_dict['primary_outcome_time_frame']):\n",
    "#     if e[0] == 20:\n",
    "#         print(f\"Index: {idx}, Value: {e}\")\n",
    "#         break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def flatten(nested_list):\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):  # 如果是子列表，递归调用 flatten 函数\n",
    "            flat_list.extend(flatten(item))\n",
    "        else:\n",
    "            flat_list.append(item)  # 否则直接添加到结果列表\n",
    "    return flat_list\n",
    "# cnt_dict['id_info_nct_id'][8125]\n",
    "times = list(set(flatten(cnt_dict['secondary_outcome_time_frame'])))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_to_num = [\n",
    "    ('one', '1'),\n",
    "    ('two', '2'),\n",
    "    ('three', '3'),\n",
    "    ('four', '4'),\n",
    "    ('five', '5'),\n",
    "    ('six', '6'),\n",
    "    ('seven', '7'),\n",
    "    ('eight', '8'),\n",
    "    ('nine', '9'),\n",
    "    ('ten', '10')\n",
    "]\n",
    "wd_2_word = [\n",
    "    (' yr ', ' year '),\n",
    "    (' yrs ', ' years '),\n",
    "    (' mo ', ' month '),\n",
    "    (' mos ', ' months '),\n",
    "    (' d ', ' day '),\n",
    "    (' ds ', ' days '),\n",
    "    (' wk ', ' week '),\n",
    "    (' wks ', ' weeks ')\n",
    "]\n",
    "def math_process(time):\n",
    "    # 英文2数字，处理简写,逗号式，合并相邻数字\n",
    "    for k,v in word_to_num:\n",
    "        time.replace(k,v)\n",
    "    for k,v in wd_2_word:\n",
    "        time.replace(k,v)\n",
    "    # time = re.sub(r'(\\d),(\\d)', r'\\1\\2', time)\n",
    "    time = time.replace(',', '')\n",
    "    match = re.search(r\"(\\d+)\\s(\\d+)\", time)\n",
    "    while match:\n",
    "        num = str(max(int(match.group(1)),int(match.group(2))))\n",
    "        time = time.replace(match.group(),num)\n",
    "        match = re.search(r\"(\\d+)\\s(\\d+)\", time)\n",
    "    match = re.search(r\"(\\d+)\\sand\\s(\\d+)\", time)\n",
    "    while match:\n",
    "        num = str(max(int(match.group(1)),int(match.group(2))))\n",
    "        time = time.replace(match.group(),num)\n",
    "        match = re.search(r\"(\\d+)\\sand\\s(\\d+)\", time)\n",
    "    return time\n",
    "\n",
    "def get_time(times):\n",
    "    # 合并数值， 处理数值\n",
    "    # 数值匹配\n",
    "    # 单位统一并选出最大值\n",
    "    for t in times:\n",
    "        t = math_process(str(t).lower())\n",
    "        print(t)\n",
    "    pass\n",
    "get_time(times[:])\n",
    "# print(math_process('up to Day 9, 30, 90 and 180'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(set(flatten(cnt_dict['tertiary_outcome'])))\n",
    "# print(set(flatten(cnt_dict['primary_outcome'])))\n",
    "# print(list({''}))\n",
    "list(set([]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def xml_file2conditions(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    conditions = [i.text for i in root.findall('condition')]\n",
    "    conditions = [i.lower() for i in conditions]\n",
    "\n",
    "    return conditions\n",
    "\n",
    "def print_conditions(LEN=len(input_file_lst)):\n",
    "    # result_dict = {}\n",
    "    for file in tqdm(input_file_lst[:LEN]):\n",
    "        result = xml_file2conditions(f\"../data/{file}\")\n",
    "        print(result)\n",
    "    return\n",
    "\n",
    "print_conditions(100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 优化text_encoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "data = pd.read_csv(f'../data/time_prediction_input.csv', sep='\\t', dtype={'masking': str, 'intervention_model': str})\n",
    "sentence_2_vec = pickle.load(open('../data/time_frame2embedding.pkl', 'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3800/3800 [00:00<00:00, 28494.83it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_2_vec = pickle.load(open('../data/time_frame2embedding.pkl', 'rb'))\n",
    "\n",
    "wd_2_word = [\n",
    "    (' yr ', ' year '),\n",
    "    (' yrs ', ' years '),\n",
    "    (' mo ', ' month '),\n",
    "    (' mos ', ' months '),\n",
    "    (' d ', ' day '),\n",
    "    (' ds ', ' days '),\n",
    "    (' wk ', ' week '),\n",
    "    (' wks ', ' weeks ')\n",
    "]\n",
    "from tqdm import tqdm\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    text = text.lower()\n",
    "    for k,v in wd_2_word:\n",
    "        text.replace(k,v)\n",
    "    text_split = text.split('\\n')\n",
    "    filter_out_empty_fn = lambda x: len(x.strip())>0\n",
    "    strip_fn = lambda x:x.strip()\n",
    "    text_split = list(filter(filter_out_empty_fn, text_split))\n",
    "    text_split = list(map(strip_fn, text_split))\n",
    "    text = ''.join(text_split)\n",
    "    return text\n",
    "\n",
    "def time_frame2embedding(text_lst):\n",
    "    text_emb=[]\n",
    "    for texts in tqdm(text_lst):\n",
    "        texts = eval(texts)\n",
    "        for i in range(len(texts)):\n",
    "            texts[i] = clean_text(texts[i])\n",
    "        if not texts:\n",
    "            # print(\"Warning: Empty text is found\")\n",
    "            text_emb.append(torch.zeros(768, dtype=torch.float32))\n",
    "        else:\n",
    "            try:\n",
    "                texts_emb, _ = torch.max(\n",
    "                    torch.stack([sentence_2_vec[text] for text in texts]), dim=0)\n",
    "                text_emb.append(texts_emb)\n",
    "                # text_emb.append(sentence_2_vec[text])\n",
    "            except:\n",
    "                print(\"Warning: Error2 text, not emb time_frame:\", texts)\n",
    "                text_emb.append(torch.zeros(768, dtype=torch.float32))\n",
    "                exit()\n",
    "    return torch.stack(text_emb)  # len(text_list), 768\n",
    "\n",
    "# title_emb = text2embedding(data['title'].tolist())\n",
    "# summary_emb = text2embedding(data['summary'].tolist())\n",
    "print(\"start\")\n",
    "# detail_emb = text2embedding(data['detail'].tolist())\n",
    "# print(data['time_frame'].tolist())\n",
    "time_frame_emb = time_frame2embedding(data['time_frame'].tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([-1.2656e-01,  7.9278e-03, -3.1774e-01,  8.3786e-02, -2.3258e-02,\n         -1.7356e-01,  2.8440e-01,  5.7807e-01, -4.6646e-01, -1.7170e-01,\n          1.2471e-01,  5.4870e-02,  1.8617e-01,  2.5144e-01,  1.4728e-01,\n          2.1588e-01, -4.9575e-01, -5.0732e-03,  3.9103e-01, -6.0163e-01,\n          1.9910e-01, -1.0090e-01,  3.4842e-03, -4.9043e-02,  5.3031e-02,\n          9.2863e-02, -1.4985e-01,  7.7242e-02,  1.3294e-01, -4.8438e-03,\n         -3.4925e-01,  3.0071e-02, -3.0298e-01,  1.0916e-01,  5.4432e-01,\n          1.2725e-01, -9.9560e-02, -1.7259e-02, -2.4105e-02, -1.1222e-01,\n          7.5558e-02, -5.1295e-02,  1.1221e-01, -5.9356e-01,  1.3076e-01,\n         -2.3687e-01, -1.7795e+00, -2.3276e-01, -7.7510e-02, -6.3919e-02,\n          1.7728e-01, -7.3679e-02,  8.9259e-01,  5.0958e-02, -5.0525e-03,\n          4.6914e-01, -1.2154e-01,  5.6035e-01, -2.0627e-01,  5.4802e-01,\n         -1.6342e-01, -1.9803e-01, -2.5869e-01,  1.7896e-01, -2.7591e-02,\n          4.1934e-01,  4.4480e-02,  3.9141e-01,  1.8871e-01,  3.5031e-01,\n         -2.2558e-01,  1.8373e-03,  3.4891e-01,  4.7995e-01, -1.0944e-01,\n         -6.6272e-01, -1.8670e-01, -8.3594e-02, -1.2805e-01, -4.6978e-01,\n          3.5674e-01, -1.2156e-02,  9.2283e-02, -1.9071e-01, -1.2425e-01,\n          4.4328e-01, -5.7437e-01, -4.9749e-01,  6.1148e-02,  6.2976e-01,\n          8.6589e-02,  4.0357e-02,  2.7454e-01,  5.0223e-01, -4.0192e-01,\n         -1.2915e-01, -3.4575e-01,  1.1682e-01,  1.4559e-01, -2.6153e-02,\n          3.0121e-01, -1.7889e-01,  5.1335e-02, -4.8658e-01,  8.2031e-03,\n          1.8445e-01, -1.5809e-01, -2.5833e-01,  1.5883e-01, -2.8640e+00,\n          3.0961e-01,  2.2659e-01, -1.8369e-01, -2.3784e-01, -1.5945e-01,\n          3.7431e-01,  5.9117e-01, -4.8810e-02, -9.1497e-02,  1.7455e-01,\n         -5.6372e-01,  4.5873e-01,  1.8314e-01, -1.8164e-01, -2.0700e-01,\n          3.1878e-01,  1.9967e-01, -3.3217e-01,  3.5453e-01, -9.4401e-02,\n         -1.0862e-01,  3.7206e-01, -3.7876e-02, -1.7435e-01, -2.1563e-01,\n         -4.4924e-01,  3.5155e-01,  1.0810e-01, -3.5231e-01, -4.1459e-01,\n         -5.4492e-01, -1.7680e-02, -2.8934e+00,  2.0027e-01,  6.4281e-01,\n          2.5321e-01,  1.5938e-01, -1.4155e-02,  3.2234e-01,  6.9497e-02,\n         -3.2374e-02, -4.5472e-01, -3.7076e-02,  4.5298e-02, -8.3169e-02,\n         -1.8935e-01, -4.9480e-02, -2.6845e-01, -1.5046e-01,  1.3503e-01,\n          2.2302e-01, -5.1421e-01,  4.2995e-02, -6.5313e-02, -4.5167e-01,\n         -1.0838e-01,  4.1203e-01,  6.4462e-01,  4.9585e-01,  2.8352e-02,\n         -3.2467e-01, -1.9047e-01,  1.5314e-01, -8.4645e-02,  1.4637e-01,\n         -1.8954e-01,  4.7794e-01,  5.3055e-01, -1.8434e-01, -2.0101e-01,\n          5.9860e-02,  2.2406e-01,  1.3821e-02,  5.3925e-03,  2.9879e-01,\n         -4.3017e-01,  4.8161e-01, -2.5235e-01, -3.1413e-01,  4.1859e-01,\n         -1.7025e-01,  2.2264e-01,  1.4480e-01,  2.8085e-01,  1.5794e-01,\n          9.6675e-02,  2.5922e-01, -1.0759e+00, -2.3155e-02,  1.9666e-01,\n         -8.7090e-02, -8.7702e-02,  1.4088e-01,  1.1202e-02,  3.2770e-02,\n          3.7387e+00,  1.5093e-01, -4.5525e-01,  8.5136e-02,  4.5019e-01,\n         -3.4043e-01,  2.5868e-01,  1.1644e-01, -2.2425e-02,  1.1742e-01,\n         -2.5057e-01,  6.4033e-01,  1.3307e-01,  9.5220e-02,  8.4657e-02,\n          1.2805e-01,  5.4927e-01,  1.1873e-01,  2.9478e-01, -5.5102e-01,\n         -4.0107e-01,  3.7843e-01,  3.4071e-01, -2.6615e-01, -1.2187e+00,\n          2.5091e-01,  1.4041e-01, -9.3722e-01,  3.2925e-01, -4.1257e-01,\n          1.5141e-01,  1.4341e-03, -4.0568e-01,  8.5449e-02, -1.2247e-01,\n          2.2522e-01,  1.3041e-01,  6.2512e-01,  6.3728e-03, -1.3647e-01,\n          4.3755e-01,  5.5154e-02, -2.4050e-01, -1.1035e-01,  9.0825e-02,\n          3.7885e-01, -6.0171e-01,  7.2836e-03, -2.1106e-01, -4.0008e-01,\n         -1.6545e-02,  9.4579e-02, -2.1795e-01, -5.0599e-02,  1.1516e-02,\n         -4.3240e-01,  1.4645e-01,  4.7808e-01, -2.7564e-01,  2.0182e-01,\n         -4.4703e-01, -2.0479e-01, -6.7341e-01, -1.2936e-01, -2.8657e-01,\n         -5.5788e-02,  4.6541e-02, -2.7997e-01, -4.3216e+00,  9.3394e-02,\n          4.6019e-01, -3.8437e-02,  1.1162e-01, -3.2448e-01,  2.1238e-01,\n          3.9977e-01,  1.3141e-01, -1.6087e-01,  3.4589e-01, -8.5866e-02,\n          1.6579e-01,  4.3685e-01, -4.2631e-01,  7.4137e-02, -1.5012e-01,\n          3.1310e-02,  1.6123e-01, -3.6093e-01,  2.8089e-01,  4.0893e-01,\n         -2.8424e-02,  1.2399e-01, -3.4457e-01,  2.7322e-01, -6.4677e-01,\n          3.1882e-01,  8.5202e-02, -3.1266e-01, -4.2020e-01, -6.0269e-01,\n         -1.6671e-01, -2.3077e-01, -4.2189e-02, -2.4702e+00,  1.7393e-01,\n         -4.3855e-01, -3.6720e-01,  1.1739e-01, -1.6839e-01,  6.9167e-01,\n         -5.8452e-02, -1.9831e-01,  7.5545e-02,  2.4088e-01,  6.9338e-02,\n         -8.1357e-02,  6.5344e-01,  3.4999e-01,  6.5040e-02,  2.5224e-01,\n         -5.5014e-02,  3.6304e-01, -1.3407e-01,  2.9797e-01, -4.8882e-02,\n         -4.9692e-02, -1.1363e-01,  3.0719e-01,  4.0089e-01, -2.9435e-02,\n         -1.4045e-01, -4.1843e-01,  2.0508e-01, -4.4724e-02, -1.8955e-01,\n         -1.7048e-01, -2.4814e-01, -1.5932e-01, -2.2746e-01,  2.8414e-01,\n          9.9434e-02,  6.8042e-01,  1.5677e-01, -2.8258e-01,  5.0766e-01,\n          2.0112e-01,  2.5816e-01,  1.4337e-01,  3.4445e-01,  2.2190e-01,\n         -4.8110e-01,  3.3995e-01,  4.5191e-01,  3.4490e-02,  3.6314e-02,\n          1.1624e+00, -1.0881e-01, -3.8588e-02, -2.9226e-02,  3.6973e-01,\n         -1.6800e-01,  1.1844e-01,  3.3793e-01,  6.6526e-01,  2.0452e-01,\n          1.6714e-01,  5.2274e-02, -5.0917e-02, -4.9432e-01,  1.3821e-01,\n         -3.3637e-01, -1.6019e-01,  1.6301e-01, -1.8498e-01, -5.8955e-02,\n         -1.5952e-01, -4.6375e-01,  5.4049e-02,  1.0177e-01, -1.1487e-03,\n          5.4001e-01,  4.2184e-01, -1.3993e-01, -1.7783e-01, -1.3908e-01,\n         -4.3940e-01,  3.7387e-01, -8.8537e-02,  5.6267e-02, -1.0500e-01,\n         -6.6576e-02, -1.8594e-01,  2.1044e-01, -3.3323e-01,  2.0663e-01,\n          6.1322e-01,  1.3150e-02, -1.4960e-01, -1.7353e-01, -7.8231e-02,\n         -8.3740e-01,  9.0843e-02, -2.8631e-01, -3.7337e-01, -2.5118e-01,\n          1.2631e-01, -2.2295e-01, -4.2986e-01, -3.8262e-01, -2.5170e-01,\n          5.7383e-01, -1.5223e-01,  2.9731e-01,  3.4935e-01,  3.1028e-01,\n         -7.6267e-02,  3.4041e-02,  1.0040e+00,  2.1230e-02, -2.8602e-01,\n          3.4244e-01, -3.6583e-02,  4.0843e-01, -1.7849e-01,  2.0487e-01,\n         -1.0419e-01, -1.9019e-01,  1.8569e-01, -3.1603e-02,  5.8273e-02,\n         -4.2203e-01, -2.4978e-01,  3.3358e-02, -1.9142e-01,  1.0670e-01,\n          9.1566e-02, -5.2950e-01, -1.6518e-01, -1.2563e-01, -3.7665e-02,\n          3.1330e-01,  9.2906e-02,  3.4315e-02,  5.7887e-03,  3.2079e-01,\n         -2.1926e-01,  4.0332e-01, -2.3220e-01,  5.0341e-01, -1.2891e-01,\n         -3.1844e-01, -3.8343e-03,  9.3989e-01, -4.0368e-02, -4.9630e-01,\n          7.0039e-02, -1.8760e-01,  8.5590e-02, -9.7070e-02,  4.6866e-01,\n         -1.9011e-01,  5.9440e-01, -1.1036e-01, -5.2720e-02,  1.2664e-01,\n         -7.8323e-01,  2.7492e-01,  2.7984e-01, -3.6752e-01,  2.4619e-01,\n         -1.6341e-01, -5.2617e-01,  4.4305e-01, -2.2568e-01, -5.0787e-02,\n         -5.4773e-01, -6.3416e-02, -1.3307e-01,  2.0046e-01,  3.2492e-01,\n          1.7157e-02,  2.7090e-01, -2.4987e-01, -1.2992e-01,  3.0435e-01,\n         -1.0747e-03,  5.5635e-01, -4.0195e-02, -3.2281e-01, -1.0748e-01,\n          1.7880e-01, -1.7486e-02,  5.4871e-01,  7.4860e-02,  1.1058e-01,\n          2.0513e-01, -2.0942e-01, -8.6351e-01,  5.6948e-02,  2.8827e-01,\n          5.9540e-01,  4.2605e-01,  6.2979e-02,  1.2142e-01,  3.9680e-01,\n         -2.3696e-01,  5.1172e-01,  1.1104e-01, -1.0787e-01,  2.0778e-01,\n          5.2907e-01, -1.7312e-01, -8.7663e-02, -3.9184e-02, -2.1578e-01,\n         -9.7245e-02,  8.5471e-02, -1.8741e-01, -1.2112e-01,  4.5259e-01,\n          7.6544e-02,  2.6375e-01, -2.5834e-01, -8.6831e-02, -1.9590e-02,\n          3.1310e-01, -4.2682e-01, -3.7673e-01,  2.0534e-01, -5.5264e-01,\n         -4.8440e-01, -1.3050e-01, -2.9925e-01, -3.0231e-01,  2.1659e-01,\n          2.9345e-01, -4.4043e-02,  1.4442e-01,  6.1321e-02, -5.8063e-01,\n          5.3640e-01, -1.4014e-01,  2.7987e-01, -7.7527e-02, -3.8535e-02,\n          2.2348e-01, -5.5214e-01, -1.5278e-01,  1.1128e-01, -1.4150e-01,\n         -7.5110e-02, -2.9214e-01, -3.4054e-01, -4.3906e-01,  1.9264e-02,\n         -7.5801e-01, -2.5985e-01,  4.5089e-01, -3.6154e-02,  1.5578e-01,\n          3.9014e-01,  4.0985e-01, -1.7697e-01, -1.3963e-03,  1.9028e-01,\n          3.6088e-02,  2.7399e-01,  2.6564e-01,  2.9422e-01,  1.9326e-01,\n          4.5486e-01,  3.7622e-01,  1.2954e-01, -3.1651e-01, -2.4693e-02,\n         -3.3952e-01,  3.2592e-01, -4.4832e-01, -3.2289e-02,  2.7852e-01,\n          1.6694e-01,  6.6716e-02, -7.4911e-02,  2.0719e+00,  5.5620e-01,\n          5.4216e-02,  2.0294e-01,  4.6045e-01, -2.2321e-01, -3.0943e-01,\n          2.8218e-01, -3.9569e-01,  5.2671e-01,  1.9144e-01, -6.4657e-03,\n         -3.4907e-01,  1.0942e-01,  3.4894e-01,  2.4106e-01, -3.5706e-01,\n         -3.3499e-01, -2.5753e-01,  1.4548e-01, -6.1592e-01,  5.0716e-01,\n          4.8831e-01, -1.6016e-01,  1.1403e-01,  2.9574e-02,  3.8541e-01,\n         -2.5210e-01,  4.7044e-02, -6.0347e-02,  4.3891e-01,  2.3947e-01,\n          1.7245e-01,  4.4478e-01,  2.0981e-01, -2.6406e-01, -1.1138e-01,\n          1.5370e-01, -1.3145e-01,  5.1172e-01, -4.7187e-02, -1.2484e-01,\n          1.4744e-01,  1.9569e-01,  5.3826e-04,  8.4002e-01, -7.8994e-02,\n         -4.3925e-01,  3.6008e-02, -3.2020e-01, -1.3108e-01, -8.7815e-02,\n         -2.4873e-01,  3.4955e-02, -3.8977e-01, -4.7523e-01,  9.5210e-02,\n          1.5316e-01,  3.3258e-01,  3.0833e-01,  1.1758e-01,  3.0798e-01,\n          1.9781e-01, -2.6348e-01,  5.3903e-01, -1.7537e-01, -8.8067e-01,\n         -2.3865e-01,  3.6275e-01, -2.6384e-01,  1.1195e-01,  5.7422e-02,\n          5.1120e-01, -3.1937e-01,  1.0655e-01, -2.0072e-01,  4.4373e-01,\n          2.2865e-01, -2.4424e-02, -3.1261e+00,  6.3657e-02, -2.1007e-01,\n          4.5480e-02,  1.8302e-01,  5.0222e-01,  1.4595e-01, -2.9360e-01,\n         -1.1545e-01, -3.4448e-01,  3.4927e-01,  2.9454e-01, -8.7401e-03,\n          1.1873e-01, -1.6775e-01,  1.6101e-01, -2.2641e-01, -1.3664e-01,\n         -4.7170e-02,  1.2568e-01, -2.7030e-01, -2.4233e-01, -4.0048e-01,\n          1.4381e-01, -1.7296e-01, -3.7581e-01,  2.7212e-01, -5.4752e-01,\n         -1.6552e-01,  3.8423e-01, -1.0125e-01,  8.0339e-01,  3.4786e-01,\n          3.0434e-01,  1.3657e-01, -2.2907e-01, -1.4546e-01, -9.5031e-02,\n          1.4595e-02,  3.5782e-01, -1.0530e-01,  3.0464e-01, -2.2489e-01,\n          4.1189e-01, -3.7331e-01,  4.5819e-01,  8.8407e-02, -4.2031e-01,\n          5.7221e-01, -3.2593e-01, -5.4248e-02,  1.5584e-01, -9.8679e-02,\n         -8.2387e-02,  2.5029e-02, -6.0537e-02,  3.0109e-01,  1.2677e-01,\n         -4.0165e-01, -4.3349e-01, -6.1329e-02, -7.1628e-03,  3.5134e-01,\n         -9.0171e-03,  1.9142e-01, -3.1668e-01, -2.2725e-01,  4.8111e-03,\n         -1.8463e-01,  1.9238e-02, -9.0078e-02, -2.4757e-01,  2.3982e-01,\n         -8.6124e-02,  1.5248e-01,  1.4870e-01,  4.6434e-01,  2.4902e-01,\n          2.7635e-01,  3.4147e-01,  2.2546e-01, -1.7475e-01, -2.5742e-01,\n          2.0641e-01,  6.4423e-02, -8.3193e+00, -3.9540e-01, -4.8666e-02,\n         -4.0367e-01,  1.6700e-01,  5.2908e-02,  4.2160e-01, -5.9056e-02,\n          3.5395e-01, -8.8154e-03,  2.9473e-01, -2.2513e-01, -1.2598e-02,\n         -7.5207e-01,  2.6589e-01,  2.8792e-01])]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "sentence_2_vec = pickle.load(open('../data/time_frame2embedding.pkl', 'rb'))\n",
    "texts = ['90 days']\n",
    "[sentence_2_vec[text] for text in texts]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
